{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# will import required packages as and when we require\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\Pandasdata\\DT_files\\sonar.csv\", header =None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "there are 208 rows (Observations) and 61 columns (Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3           4   \\\n",
       "count   208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean      0.029164    0.038437    0.043832    0.053892    0.075202   \n",
       "std       0.022991    0.032960    0.038428    0.046528    0.055552   \n",
       "min       0.001500    0.000600    0.001500    0.005800    0.006700   \n",
       "25%       0.013350    0.016450    0.018950    0.024375    0.038050   \n",
       "50%       0.022800    0.030800    0.034300    0.044050    0.062500   \n",
       "75%       0.035550    0.047950    0.057950    0.064500    0.100275   \n",
       "max       0.137100    0.233900    0.305900    0.426400    0.401000   \n",
       "\n",
       "                5           6           7           8           9   ...  \\\n",
       "count   208.000000  208.000000  208.000000  208.000000  208.000000  ...   \n",
       "unique         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "top            NaN         NaN         NaN         NaN         NaN  ...   \n",
       "freq           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "mean      0.104570    0.121747    0.134799    0.178003    0.208259  ...   \n",
       "std       0.059105    0.061788    0.085152    0.118387    0.134416  ...   \n",
       "min       0.010200    0.003300    0.005500    0.007500    0.011300  ...   \n",
       "25%       0.067025    0.080900    0.080425    0.097025    0.111275  ...   \n",
       "50%       0.092150    0.106950    0.112100    0.152250    0.182400  ...   \n",
       "75%       0.134125    0.154000    0.169600    0.233425    0.268700  ...   \n",
       "max       0.382300    0.372900    0.459000    0.682800    0.710600  ...   \n",
       "\n",
       "                51          52          53          54          55  \\\n",
       "count   208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean      0.013420    0.010709    0.010941    0.009290    0.008222   \n",
       "std       0.009634    0.007060    0.007301    0.007088    0.005736   \n",
       "min       0.000800    0.000500    0.001000    0.000600    0.000400   \n",
       "25%       0.007275    0.005075    0.005375    0.004150    0.004400   \n",
       "50%       0.011400    0.009550    0.009300    0.007500    0.006850   \n",
       "75%       0.016725    0.014900    0.014500    0.012100    0.010575   \n",
       "max       0.070900    0.039000    0.035200    0.044700    0.039400   \n",
       "\n",
       "                56          57          58          59   60  \n",
       "count   208.000000  208.000000  208.000000  208.000000  208  \n",
       "unique         NaN         NaN         NaN         NaN    2  \n",
       "top            NaN         NaN         NaN         NaN    M  \n",
       "freq           NaN         NaN         NaN         NaN  111  \n",
       "mean      0.007820    0.007949    0.007941    0.006507  NaN  \n",
       "std       0.005785    0.006470    0.006181    0.005031  NaN  \n",
       "min       0.000300    0.000300    0.000100    0.000600  NaN  \n",
       "25%       0.003700    0.003600    0.003675    0.003100  NaN  \n",
       "50%       0.005950    0.005800    0.006400    0.005300  NaN  \n",
       "75%       0.010425    0.010350    0.010325    0.008525  NaN  \n",
       "max       0.035500    0.044000    0.036400    0.043900  NaN  \n",
       "\n",
       "[11 rows x 61 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include ='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean is greater than median, That means the data is right skewed\n",
    "# we can clearly see that there are few outliers in the data.\n",
    "# The data is inbetween 0 and 1. I.e it is already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     float64\n",
       "1     float64\n",
       "2     float64\n",
       "3     float64\n",
       "4     float64\n",
       "5     float64\n",
       "6     float64\n",
       "7     float64\n",
       "8     float64\n",
       "9     float64\n",
       "10    float64\n",
       "11    float64\n",
       "12    float64\n",
       "13    float64\n",
       "14    float64\n",
       "15    float64\n",
       "16    float64\n",
       "17    float64\n",
       "18    float64\n",
       "19    float64\n",
       "20    float64\n",
       "21    float64\n",
       "22    float64\n",
       "23    float64\n",
       "24    float64\n",
       "25    float64\n",
       "26    float64\n",
       "27    float64\n",
       "28    float64\n",
       "29    float64\n",
       "       ...   \n",
       "31    float64\n",
       "32    float64\n",
       "33    float64\n",
       "34    float64\n",
       "35    float64\n",
       "36    float64\n",
       "37    float64\n",
       "38    float64\n",
       "39    float64\n",
       "40    float64\n",
       "41    float64\n",
       "42    float64\n",
       "43    float64\n",
       "44    float64\n",
       "45    float64\n",
       "46    float64\n",
       "47    float64\n",
       "48    float64\n",
       "49    float64\n",
       "50    float64\n",
       "51    float64\n",
       "52    float64\n",
       "53    float64\n",
       "54    float64\n",
       "55    float64\n",
       "56    float64\n",
       "57    float64\n",
       "58    float64\n",
       "59    float64\n",
       "60     object\n",
       "Length: 61, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us check the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    0\n",
       "20    0\n",
       "21    0\n",
       "22    0\n",
       "23    0\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    0\n",
       "29    0\n",
       "     ..\n",
       "31    0\n",
       "32    0\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "36    0\n",
       "37    0\n",
       "38    0\n",
       "39    0\n",
       "40    0\n",
       "41    0\n",
       "42    0\n",
       "43    0\n",
       "44    0\n",
       "45    0\n",
       "46    0\n",
       "47    0\n",
       "48    0\n",
       "49    0\n",
       "50    0\n",
       "51    0\n",
       "52    0\n",
       "53    0\n",
       "54    0\n",
       "55    0\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20fec295898>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no null values/Nan values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R' 'M']\n",
      "M    111\n",
      "R     97\n",
      "Name: 60, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# the problem is a classification problem.\n",
    "print(df[60].unique())\n",
    "print(df[60].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20ff6118e80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=df[60], data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will convert R & M in to 0 and 1 by using get dummies or label encoder\n",
    "x = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will convert the 'x' in to an array using numpy\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02  , 0.0371, 0.0428, ..., 0.0084, 0.009 , 0.0032],\n",
       "       [0.0453, 0.0523, 0.0843, ..., 0.0049, 0.0052, 0.0044],\n",
       "       [0.0262, 0.0582, 0.1099, ..., 0.0164, 0.0095, 0.0078],\n",
       "       ...,\n",
       "       [0.0522, 0.0437, 0.018 , ..., 0.0138, 0.0077, 0.0031],\n",
       "       [0.0303, 0.0353, 0.049 , ..., 0.0079, 0.0036, 0.0048],\n",
       "       [0.026 , 0.0363, 0.0136, ..., 0.0036, 0.0061, 0.0115]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as this is a classification problem, we take in consideration of F1 score of the model. Higher the F1 Score, greater the accuracy\n",
    "\n",
    "# different algorithms for clasification problem are \n",
    "# 1. Logistic regression\n",
    "# 2. Decission Tree Classifier\n",
    "# 2. KNN Classifier\n",
    "# 3. SVM (SVC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score corresponding to random state:  42 is:  0.8125\n",
      "f1 score corresponding to random state:  43 is:  0.7804878048780487\n",
      "f1 score corresponding to random state:  44 is:  0.6285714285714286\n",
      "f1 score corresponding to random state:  45 is:  0.7692307692307693\n",
      "f1 score corresponding to random state:  46 is:  0.6829268292682927\n",
      "f1 score corresponding to random state:  47 is:  0.7500000000000001\n",
      "f1 score corresponding to random state:  48 is:  0.7999999999999999\n",
      "f1 score corresponding to random state:  49 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  50 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  51 is:  0.7659574468085107\n",
      "f1 score corresponding to random state:  52 is:  0.75\n",
      "f1 score corresponding to random state:  53 is:  0.5161290322580645\n",
      "f1 score corresponding to random state:  54 is:  0.6896551724137931\n",
      "f1 score corresponding to random state:  55 is:  0.7333333333333333\n",
      "f1 score corresponding to random state:  56 is:  0.761904761904762\n",
      "f1 score corresponding to random state:  57 is:  0.8125000000000001\n",
      "f1 score corresponding to random state:  58 is:  0.7878787878787877\n",
      "f1 score corresponding to random state:  59 is:  0.7027027027027026\n",
      "f1 score corresponding to random state:  60 is:  0.6111111111111112\n",
      "f1 score corresponding to random state:  61 is:  0.5454545454545454\n",
      "f1 score corresponding to random state:  62 is:  0.8260869565217391\n",
      "f1 score corresponding to random state:  63 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  64 is:  0.606060606060606\n",
      "f1 score corresponding to random state:  65 is:  0.7083333333333334\n",
      "f1 score corresponding to random state:  66 is:  0.6428571428571429\n",
      "f1 score corresponding to random state:  67 is:  0.8108108108108109\n",
      "f1 score corresponding to random state:  68 is:  0.7058823529411765\n",
      "f1 score corresponding to random state:  69 is:  0.7317073170731706\n",
      "f1 score corresponding to random state:  70 is:  0.6486486486486486\n",
      "f1 score corresponding to random state:  71 is:  0.7027027027027027\n",
      "f1 score corresponding to random state:  72 is:  0.7142857142857143\n",
      "f1 score corresponding to random state:  73 is:  0.7804878048780488\n",
      "f1 score corresponding to random state:  74 is:  0.7647058823529411\n",
      "f1 score corresponding to random state:  75 is:  0.6842105263157895\n",
      "f1 score corresponding to random state:  76 is:  0.7804878048780488\n",
      "f1 score corresponding to random state:  77 is:  0.7058823529411764\n",
      "f1 score corresponding to random state:  78 is:  0.7272727272727272\n",
      "f1 score corresponding to random state:  79 is:  0.6470588235294117\n",
      "f1 score corresponding to random state:  80 is:  0.7441860465116279\n",
      "f1 score corresponding to random state:  81 is:  0.6857142857142857\n",
      "f1 score corresponding to random state:  82 is:  0.7027027027027027\n",
      "f1 score corresponding to random state:  83 is:  0.7142857142857143\n",
      "f1 score corresponding to random state:  84 is:  0.7222222222222223\n",
      "f1 score corresponding to random state:  85 is:  0.7368421052631577\n",
      "f1 score corresponding to random state:  86 is:  0.7906976744186046\n",
      "f1 score corresponding to random state:  87 is:  0.5806451612903226\n",
      "f1 score corresponding to random state:  88 is:  0.7906976744186046\n",
      "f1 score corresponding to random state:  89 is:  0.8421052631578947\n",
      "f1 score corresponding to random state:  90 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  91 is:  0.5945945945945946\n",
      "f1 score corresponding to random state:  92 is:  0.7647058823529412\n",
      "f1 score corresponding to random state:  93 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  94 is:  0.6486486486486486\n",
      "f1 score corresponding to random state:  95 is:  0.8181818181818182\n",
      "f1 score corresponding to random state:  96 is:  0.7368421052631577\n",
      "f1 score corresponding to random state:  97 is:  0.6341463414634146\n",
      "f1 score corresponding to random state:  98 is:  0.7857142857142857\n",
      "f1 score corresponding to random state:  99 is:  0.8444444444444444\n",
      "f1 score corresponding to random state:  100 is:  0.75\n",
      "f1 score corresponding to random state:  101 is:  0.7906976744186046\n",
      "f1 score corresponding to random state:  102 is:  0.7\n",
      "f1 score corresponding to random state:  103 is:  0.7333333333333334\n",
      "f1 score corresponding to random state:  104 is:  0.7391304347826088\n",
      "f1 score corresponding to random state:  105 is:  0.7999999999999999\n",
      "f1 score corresponding to random state:  106 is:  0.611111111111111\n",
      "f1 score corresponding to random state:  107 is:  0.742857142857143\n",
      "f1 score corresponding to random state:  108 is:  0.625\n",
      "f1 score corresponding to random state:  109 is:  0.65\n",
      "f1 score corresponding to random state:  110 is:  0.6060606060606061\n",
      "f1 score corresponding to random state:  111 is:  0.7096774193548387\n",
      "f1 score corresponding to random state:  112 is:  0.7500000000000001\n",
      "f1 score corresponding to random state:  113 is:  0.6486486486486486\n",
      "f1 score corresponding to random state:  114 is:  0.7058823529411764\n",
      "f1 score corresponding to random state:  115 is:  0.5882352941176471\n",
      "f1 score corresponding to random state:  116 is:  0.7659574468085107\n",
      "f1 score corresponding to random state:  117 is:  0.7692307692307692\n",
      "f1 score corresponding to random state:  118 is:  0.8571428571428572\n",
      "f1 score corresponding to random state:  119 is:  0.5294117647058824\n",
      "f1 score corresponding to random state:  120 is:  0.7179487179487181\n",
      "f1 score corresponding to random state:  121 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  122 is:  0.6486486486486486\n",
      "f1 score corresponding to random state:  123 is:  0.7692307692307692\n",
      "f1 score corresponding to random state:  124 is:  0.8387096774193549\n",
      "f1 score corresponding to random state:  125 is:  0.7999999999999999\n",
      "f1 score corresponding to random state:  126 is:  0.6250000000000001\n",
      "f1 score corresponding to random state:  127 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  128 is:  0.7777777777777778\n",
      "f1 score corresponding to random state:  129 is:  0.742857142857143\n",
      "f1 score corresponding to random state:  130 is:  0.7647058823529411\n",
      "f1 score corresponding to random state:  131 is:  0.6285714285714287\n",
      "f1 score corresponding to random state:  132 is:  0.6428571428571429\n",
      "f1 score corresponding to random state:  133 is:  0.7368421052631577\n",
      "f1 score corresponding to random state:  134 is:  0.7647058823529411\n",
      "f1 score corresponding to random state:  135 is:  0.7647058823529411\n",
      "f1 score corresponding to random state:  136 is:  0.7222222222222223\n",
      "f1 score corresponding to random state:  137 is:  0.7999999999999999\n",
      "f1 score corresponding to random state:  138 is:  0.6857142857142857\n",
      "f1 score corresponding to random state:  139 is:  0.5333333333333333\n",
      "f1 score corresponding to random state:  140 is:  0.8484848484848485\n",
      "f1 score corresponding to random state:  141 is:  0.6451612903225806\n",
      "f1 score corresponding to random state:  142 is:  0.7567567567567567\n",
      "f1 score corresponding to random state:  143 is:  0.6470588235294117\n",
      "f1 score corresponding to random state:  144 is:  0.7142857142857143\n",
      "f1 score corresponding to random state:  145 is:  0.7058823529411765\n",
      "f1 score corresponding to random state:  146 is:  0.7906976744186046\n",
      "f1 score corresponding to random state:  147 is:  0.5925925925925926\n",
      "f1 score corresponding to random state:  148 is:  0.7567567567567567\n",
      "f1 score corresponding to random state:  149 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  150 is:  0.631578947368421\n",
      "f1 score corresponding to random state:  151 is:  0.5714285714285715\n",
      "f1 score corresponding to random state:  152 is:  0.8\n",
      "f1 score corresponding to random state:  153 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  154 is:  0.6451612903225806\n",
      "f1 score corresponding to random state:  155 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  156 is:  0.6896551724137931\n",
      "f1 score corresponding to random state:  157 is:  0.7142857142857143\n",
      "f1 score corresponding to random state:  158 is:  0.5714285714285715\n",
      "f1 score corresponding to random state:  159 is:  0.7058823529411765\n",
      "f1 score corresponding to random state:  160 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  161 is:  0.5714285714285715\n",
      "f1 score corresponding to random state:  162 is:  0.8444444444444444\n",
      "f1 score corresponding to random state:  163 is:  0.7317073170731708\n",
      "f1 score corresponding to random state:  164 is:  0.8095238095238095\n",
      "f1 score corresponding to random state:  165 is:  0.6111111111111113\n",
      "f1 score corresponding to random state:  166 is:  0.5454545454545454\n",
      "f1 score corresponding to random state:  167 is:  0.7027027027027025\n",
      "f1 score corresponding to random state:  168 is:  0.8125\n",
      "f1 score corresponding to random state:  169 is:  0.7272727272727273\n",
      "f1 score corresponding to random state:  170 is:  0.7096774193548386\n",
      "f1 score corresponding to random state:  171 is:  0.7368421052631577\n",
      "f1 score corresponding to random state:  172 is:  0.717948717948718\n",
      "f1 score corresponding to random state:  173 is:  0.6249999999999999\n",
      "f1 score corresponding to random state:  174 is:  0.6829268292682926\n",
      "f1 score corresponding to random state:  175 is:  0.7000000000000001\n",
      "f1 score corresponding to random state:  176 is:  0.625\n",
      "f1 score corresponding to random state:  177 is:  0.7000000000000001\n",
      "f1 score corresponding to random state:  178 is:  0.5625\n",
      "f1 score corresponding to random state:  179 is:  0.7272727272727272\n",
      "f1 score corresponding to random state:  180 is:  0.7727272727272727\n",
      "f1 score corresponding to random state:  181 is:  0.7368421052631577\n",
      "f1 score corresponding to random state:  182 is:  0.6666666666666665\n",
      "f1 score corresponding to random state:  183 is:  0.7647058823529413\n",
      "f1 score corresponding to random state:  184 is:  0.7407407407407406\n",
      "f1 score corresponding to random state:  185 is:  0.7027027027027026\n",
      "f1 score corresponding to random state:  186 is:  0.5789473684210527\n",
      "f1 score corresponding to random state:  187 is:  0.7272727272727274\n",
      "f1 score corresponding to random state:  188 is:  0.625\n",
      "f1 score corresponding to random state:  189 is:  0.8205128205128205\n",
      "f1 score corresponding to random state:  190 is:  0.6829268292682926\n",
      "f1 score corresponding to random state:  191 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  192 is:  0.782608695652174\n",
      "f1 score corresponding to random state:  193 is:  0.8205128205128205\n",
      "f1 score corresponding to random state:  194 is:  0.6666666666666667\n",
      "f1 score corresponding to random state:  195 is:  0.8333333333333334\n",
      "f1 score corresponding to random state:  196 is:  0.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score corresponding to random state:  197 is:  0.7333333333333334\n",
      "f1 score corresponding to random state:  198 is:  0.8205128205128205\n",
      "f1 score corresponding to random state:  199 is:  0.823529411764706\n",
      "f1 score corresponding to random state:  200 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  201 is:  0.4000000000000001\n",
      "f1 score corresponding to random state:  202 is:  0.7027027027027027\n",
      "f1 score corresponding to random state:  203 is:  0.7000000000000001\n",
      "f1 score corresponding to random state:  204 is:  0.85\n",
      "f1 score corresponding to random state:  205 is:  0.6666666666666666\n",
      "f1 score corresponding to random state:  206 is:  0.6976744186046512\n",
      "f1 score corresponding to random state:  207 is:  0.6875\n",
      "f1 score corresponding to random state:  208 is:  0.8484848484848484\n",
      "Max f2 score corresponding to  118 is:  0.8571428571428572\n"
     ]
    }
   ],
   "source": [
    "# We will find for which random state the f1 score is maximum\n",
    "max_f1score = 0\n",
    "for r_state in range(42,209):\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(x,y,random_state = r_state, test_size = 0.2)\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(xtrain,ytrain)\n",
    "    pred = lr.predict(xtest)\n",
    "    f1score = f1_score(ytest,pred)\n",
    "    print(\"f1 score corresponding to random state: \",r_state,\"is: \", f1score )\n",
    "    \n",
    "    if f1score > max_f1score:\n",
    "        max_f1score = f1score\n",
    "        final_r_state = r_state \n",
    "        \n",
    "print(\"Max f1 score corresponding to \",final_r_state, \"is: \", max_f1score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at random state of 118 we got f1 score as 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6109754471310535"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will see the cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr, x,y,cv=5, scoring = 'f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score corresponding to random state 42 is: 0.5789473684210527\n",
      "f1 score corresponding to random state 43 is: 0.6818181818181818\n",
      "f1 score corresponding to random state 44 is: 0.5641025641025642\n",
      "f1 score corresponding to random state 45 is: 0.6818181818181819\n",
      "f1 score corresponding to random state 46 is: 0.7755102040816326\n",
      "f1 score corresponding to random state 47 is: 0.76\n",
      "f1 score corresponding to random state 48 is: 0.5555555555555556\n",
      "f1 score corresponding to random state 49 is: 0.6274509803921569\n",
      "f1 score corresponding to random state 50 is: 0.7368421052631579\n",
      "f1 score corresponding to random state 51 is: 0.7111111111111111\n",
      "f1 score corresponding to random state 52 is: 0.8095238095238095\n",
      "f1 score corresponding to random state 53 is: 0.5882352941176471\n",
      "f1 score corresponding to random state 54 is: 0.5882352941176471\n",
      "f1 score corresponding to random state 55 is: 0.5333333333333333\n",
      "f1 score corresponding to random state 56 is: 0.761904761904762\n",
      "f1 score corresponding to random state 57 is: 0.6428571428571429\n",
      "f1 score corresponding to random state 58 is: 0.6470588235294117\n",
      "f1 score corresponding to random state 59 is: 0.6666666666666665\n",
      "f1 score corresponding to random state 60 is: 0.7000000000000001\n",
      "f1 score corresponding to random state 61 is: 0.631578947368421\n",
      "f1 score corresponding to random state 62 is: 0.7391304347826088\n",
      "f1 score corresponding to random state 63 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 64 is: 0.5882352941176471\n",
      "f1 score corresponding to random state 65 is: 0.6122448979591836\n",
      "f1 score corresponding to random state 66 is: 0.5714285714285714\n",
      "f1 score corresponding to random state 67 is: 0.8333333333333333\n",
      "f1 score corresponding to random state 68 is: 0.7000000000000001\n",
      "f1 score corresponding to random state 69 is: 0.7272727272727272\n",
      "f1 score corresponding to random state 70 is: 0.6\n",
      "f1 score corresponding to random state 71 is: 0.6315789473684211\n",
      "f1 score corresponding to random state 72 is: 0.761904761904762\n",
      "f1 score corresponding to random state 73 is: 0.7317073170731706\n",
      "f1 score corresponding to random state 74 is: 0.8095238095238096\n",
      "f1 score corresponding to random state 75 is: 0.711111111111111\n",
      "f1 score corresponding to random state 76 is: 0.7804878048780488\n",
      "f1 score corresponding to random state 77 is: 0.761904761904762\n",
      "f1 score corresponding to random state 78 is: 0.6829268292682927\n",
      "f1 score corresponding to random state 79 is: 0.7317073170731707\n",
      "f1 score corresponding to random state 80 is: 0.7234042553191491\n",
      "f1 score corresponding to random state 81 is: 0.6829268292682926\n",
      "f1 score corresponding to random state 82 is: 0.7500000000000001\n",
      "f1 score corresponding to random state 83 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 84 is: 0.6111111111111112\n",
      "f1 score corresponding to random state 85 is: 0.6829268292682926\n",
      "f1 score corresponding to random state 86 is: 0.7555555555555555\n",
      "f1 score corresponding to random state 87 is: 0.6486486486486486\n",
      "f1 score corresponding to random state 88 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 89 is: 0.6829268292682926\n",
      "f1 score corresponding to random state 90 is: 0.7317073170731707\n",
      "f1 score corresponding to random state 91 is: 0.8292682926829269\n",
      "f1 score corresponding to random state 92 is: 0.717948717948718\n",
      "f1 score corresponding to random state 93 is: 0.6285714285714286\n",
      "f1 score corresponding to random state 94 is: 0.8085106382978724\n",
      "f1 score corresponding to random state 95 is: 0.7272727272727273\n",
      "f1 score corresponding to random state 96 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 97 is: 0.6808510638297872\n",
      "f1 score corresponding to random state 98 is: 0.6111111111111112\n",
      "f1 score corresponding to random state 99 is: 0.7906976744186046\n",
      "f1 score corresponding to random state 100 is: 0.6857142857142857\n",
      "f1 score corresponding to random state 101 is: 0.8181818181818182\n",
      "f1 score corresponding to random state 102 is: 0.742857142857143\n",
      "f1 score corresponding to random state 103 is: 0.6250000000000001\n",
      "f1 score corresponding to random state 104 is: 0.8846153846153846\n",
      "f1 score corresponding to random state 105 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 106 is: 0.6857142857142857\n",
      "f1 score corresponding to random state 107 is: 0.7692307692307692\n",
      "f1 score corresponding to random state 108 is: 0.6486486486486486\n",
      "f1 score corresponding to random state 109 is: 0.7804878048780487\n",
      "f1 score corresponding to random state 110 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 111 is: 0.7567567567567567\n",
      "f1 score corresponding to random state 112 is: 0.7804878048780488\n",
      "f1 score corresponding to random state 113 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 114 is: 0.7894736842105262\n",
      "f1 score corresponding to random state 115 is: 0.5945945945945946\n",
      "f1 score corresponding to random state 116 is: 0.7755102040816326\n",
      "f1 score corresponding to random state 117 is: 0.6153846153846153\n",
      "f1 score corresponding to random state 118 is: 0.7234042553191491\n",
      "f1 score corresponding to random state 119 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 120 is: 0.7142857142857143\n",
      "f1 score corresponding to random state 121 is: 0.7500000000000001\n",
      "f1 score corresponding to random state 122 is: 0.7317073170731706\n",
      "f1 score corresponding to random state 123 is: 0.6976744186046512\n",
      "f1 score corresponding to random state 124 is: 0.7096774193548386\n",
      "f1 score corresponding to random state 125 is: 0.8260869565217391\n",
      "f1 score corresponding to random state 126 is: 0.588235294117647\n",
      "f1 score corresponding to random state 127 is: 0.6511627906976745\n",
      "f1 score corresponding to random state 128 is: 0.4848484848484848\n",
      "f1 score corresponding to random state 129 is: 0.7027027027027027\n",
      "f1 score corresponding to random state 130 is: 0.7804878048780488\n",
      "f1 score corresponding to random state 131 is: 0.7222222222222222\n",
      "f1 score corresponding to random state 132 is: 0.6428571428571429\n",
      "f1 score corresponding to random state 133 is: 0.7200000000000001\n",
      "f1 score corresponding to random state 134 is: 0.75\n",
      "f1 score corresponding to random state 135 is: 0.7567567567567567\n",
      "f1 score corresponding to random state 136 is: 0.6153846153846154\n",
      "f1 score corresponding to random state 137 is: 0.6111111111111112\n",
      "f1 score corresponding to random state 138 is: 0.6829268292682926\n",
      "f1 score corresponding to random state 139 is: 0.7777777777777778\n",
      "f1 score corresponding to random state 140 is: 0.7058823529411765\n",
      "f1 score corresponding to random state 141 is: 0.6060606060606061\n",
      "f1 score corresponding to random state 142 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 143 is: 0.7441860465116279\n",
      "f1 score corresponding to random state 144 is: 0.7368421052631579\n",
      "f1 score corresponding to random state 145 is: 0.5714285714285714\n",
      "f1 score corresponding to random state 146 is: 0.65\n",
      "f1 score corresponding to random state 147 is: 0.5714285714285715\n",
      "f1 score corresponding to random state 148 is: 0.6111111111111113\n",
      "f1 score corresponding to random state 149 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 150 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 151 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 152 is: 0.5714285714285715\n",
      "f1 score corresponding to random state 153 is: 0.7272727272727272\n",
      "f1 score corresponding to random state 154 is: 0.6285714285714287\n",
      "f1 score corresponding to random state 155 is: 0.6111111111111112\n",
      "f1 score corresponding to random state 156 is: 0.75\n",
      "f1 score corresponding to random state 157 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 158 is: 0.6470588235294118\n",
      "f1 score corresponding to random state 159 is: 0.7368421052631577\n",
      "f1 score corresponding to random state 160 is: 0.7317073170731707\n",
      "f1 score corresponding to random state 161 is: 0.7222222222222223\n",
      "f1 score corresponding to random state 162 is: 0.8749999999999999\n",
      "f1 score corresponding to random state 163 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 164 is: 0.7441860465116279\n",
      "f1 score corresponding to random state 165 is: 0.7058823529411765\n",
      "f1 score corresponding to random state 166 is: 0.717948717948718\n",
      "f1 score corresponding to random state 167 is: 0.6530612244897959\n",
      "f1 score corresponding to random state 168 is: 0.7333333333333333\n",
      "f1 score corresponding to random state 169 is: 0.7027027027027027\n",
      "f1 score corresponding to random state 170 is: 0.6111111111111112\n",
      "f1 score corresponding to random state 171 is: 0.6976744186046512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score corresponding to random state 172 is: 0.6153846153846153\n",
      "f1 score corresponding to random state 173 is: 0.6511627906976744\n",
      "f1 score corresponding to random state 174 is: 0.7727272727272727\n",
      "f1 score corresponding to random state 175 is: 0.6818181818181818\n",
      "f1 score corresponding to random state 176 is: 0.6222222222222222\n",
      "f1 score corresponding to random state 177 is: 0.7317073170731707\n",
      "f1 score corresponding to random state 178 is: 0.5641025641025642\n",
      "f1 score corresponding to random state 179 is: 0.7647058823529412\n",
      "f1 score corresponding to random state 180 is: 0.7142857142857143\n",
      "f1 score corresponding to random state 181 is: 0.7441860465116279\n",
      "f1 score corresponding to random state 182 is: 0.7272727272727272\n",
      "f1 score corresponding to random state 183 is: 0.6486486486486486\n",
      "f1 score corresponding to random state 184 is: 0.6875\n",
      "f1 score corresponding to random state 185 is: 0.6842105263157895\n",
      "f1 score corresponding to random state 186 is: 0.5789473684210527\n",
      "f1 score corresponding to random state 187 is: 0.8205128205128205\n",
      "f1 score corresponding to random state 188 is: 0.6285714285714287\n",
      "f1 score corresponding to random state 189 is: 0.6153846153846153\n",
      "f1 score corresponding to random state 190 is: 0.7916666666666666\n",
      "f1 score corresponding to random state 191 is: 0.6829268292682926\n",
      "f1 score corresponding to random state 192 is: 0.7755102040816326\n",
      "f1 score corresponding to random state 193 is: 0.6470588235294117\n",
      "f1 score corresponding to random state 194 is: 0.7027027027027027\n",
      "f1 score corresponding to random state 195 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 196 is: 0.6341463414634148\n",
      "f1 score corresponding to random state 197 is: 0.5\n",
      "f1 score corresponding to random state 198 is: 0.7317073170731707\n",
      "f1 score corresponding to random state 199 is: 0.7317073170731707\n",
      "f1 score corresponding to random state 200 is: 0.6666666666666665\n",
      "f1 score corresponding to random state 201 is: 0.5454545454545454\n",
      "f1 score corresponding to random state 202 is: 0.7027027027027027\n",
      "f1 score corresponding to random state 203 is: 0.7659574468085107\n",
      "f1 score corresponding to random state 204 is: 0.7027027027027027\n",
      "f1 score corresponding to random state 205 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 206 is: 0.5652173913043479\n",
      "f1 score corresponding to random state 207 is: 0.4864864864864864\n",
      "f1 score corresponding to random state 208 is: 0.717948717948718\n",
      "Max f2 score corresponding to  104 is:  0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "max_f1score = 0\n",
    "\n",
    "for r_state in range(42, 209):\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(x,y,random_state = r_state, test_size = 0.2)\n",
    "    \n",
    "    dc = DecisionTreeClassifier()\n",
    "    dc.fit(xtrain,ytrain)\n",
    "    pred = dc.predict(xtest)\n",
    "    f1score = f1_score(ytest,pred)\n",
    "    \n",
    "    print(\"f1 score corresponding to random state\", r_state, \"is:\", f1score)\n",
    "    \n",
    "    if f1score > max_f1score:\n",
    "        max_f1score =f1score\n",
    "        final_r_state = r_state\n",
    "print(\"Max f1 score corresponding to \",final_r_state, \"is: \", max_f1score)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at random state 104 we got 0.88 as max f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6112553159585634"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(dc, x,y, cv =5, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# we dont know how many neighbours we need to consider. so we are using gridsearchCV for this\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "neighbors ={\"n_neighbors\": range(1,10)}\n",
    "\n",
    "gsv = GridSearchCV(knn,neighbors, cv =5, scoring ='f1')\n",
    "gsv.fit(x,y)\n",
    "gsv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best no of neighbors is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score corresponding to random state 42 is: 0.8484848484848485\n",
      "f1 score corresponding to random state 43 is: 0.744186046511628\n",
      "f1 score corresponding to random state 44 is: 0.6666666666666667\n",
      "f1 score corresponding to random state 45 is: 0.8571428571428571\n",
      "f1 score corresponding to random state 46 is: 0.8085106382978724\n",
      "f1 score corresponding to random state 47 is: 0.7659574468085107\n",
      "f1 score corresponding to random state 48 is: 0.8205128205128205\n",
      "f1 score corresponding to random state 49 is: 0.7894736842105263\n",
      "f1 score corresponding to random state 50 is: 0.8000000000000002\n",
      "f1 score corresponding to random state 51 is: 0.92\n",
      "f1 score corresponding to random state 52 is: 0.8571428571428571\n",
      "f1 score corresponding to random state 53 is: 0.631578947368421\n",
      "f1 score corresponding to random state 54 is: 0.6428571428571429\n",
      "f1 score corresponding to random state 55 is: 0.6875\n",
      "f1 score corresponding to random state 56 is: 0.85\n",
      "f1 score corresponding to random state 57 is: 0.8387096774193549\n",
      "f1 score corresponding to random state 58 is: 0.7647058823529413\n",
      "f1 score corresponding to random state 59 is: 0.6451612903225806\n",
      "f1 score corresponding to random state 60 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 61 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 62 is: 0.8372093023255814\n",
      "f1 score corresponding to random state 63 is: 0.8461538461538461\n",
      "f1 score corresponding to random state 64 is: 0.8333333333333333\n",
      "f1 score corresponding to random state 65 is: 0.8260869565217391\n",
      "f1 score corresponding to random state 66 is: 0.6896551724137931\n",
      "f1 score corresponding to random state 67 is: 0.8571428571428572\n",
      "f1 score corresponding to random state 68 is: 0.7407407407407408\n",
      "f1 score corresponding to random state 69 is: 0.7441860465116279\n",
      "f1 score corresponding to random state 70 is: 0.7567567567567567\n",
      "f1 score corresponding to random state 71 is: 0.7272727272727272\n",
      "f1 score corresponding to random state 72 is: 0.888888888888889\n",
      "f1 score corresponding to random state 73 is: 0.7692307692307692\n",
      "f1 score corresponding to random state 74 is: 0.7222222222222222\n",
      "f1 score corresponding to random state 75 is: 0.7692307692307693\n",
      "f1 score corresponding to random state 76 is: 0.6829268292682926\n",
      "f1 score corresponding to random state 77 is: 0.8205128205128205\n",
      "f1 score corresponding to random state 78 is: 0.8181818181818181\n",
      "f1 score corresponding to random state 79 is: 0.8108108108108109\n",
      "f1 score corresponding to random state 80 is: 0.8749999999999999\n",
      "f1 score corresponding to random state 81 is: 0.8\n",
      "f1 score corresponding to random state 82 is: 0.8571428571428572\n",
      "f1 score corresponding to random state 83 is: 0.7567567567567567\n",
      "f1 score corresponding to random state 84 is: 0.8108108108108107\n",
      "f1 score corresponding to random state 85 is: 0.7368421052631577\n",
      "f1 score corresponding to random state 86 is: 0.7804878048780488\n",
      "f1 score corresponding to random state 87 is: 0.787878787878788\n",
      "f1 score corresponding to random state 88 is: 0.8\n",
      "f1 score corresponding to random state 89 is: 0.717948717948718\n",
      "f1 score corresponding to random state 90 is: 0.8181818181818182\n",
      "f1 score corresponding to random state 91 is: 0.8421052631578947\n",
      "f1 score corresponding to random state 92 is: 0.8\n",
      "f1 score corresponding to random state 93 is: 0.7878787878787878\n",
      "f1 score corresponding to random state 94 is: 0.7804878048780488\n",
      "f1 score corresponding to random state 95 is: 0.9302325581395349\n",
      "f1 score corresponding to random state 96 is: 0.7222222222222223\n",
      "f1 score corresponding to random state 97 is: 0.8095238095238095\n",
      "f1 score corresponding to random state 98 is: 0.8387096774193549\n",
      "f1 score corresponding to random state 99 is: 0.7916666666666667\n",
      "f1 score corresponding to random state 100 is: 0.8666666666666666\n",
      "f1 score corresponding to random state 101 is: 0.7500000000000001\n",
      "f1 score corresponding to random state 102 is: 0.8\n",
      "f1 score corresponding to random state 103 is: 0.7142857142857143\n",
      "f1 score corresponding to random state 104 is: 0.8510638297872339\n",
      "f1 score corresponding to random state 105 is: 0.8421052631578948\n",
      "f1 score corresponding to random state 106 is: 0.7222222222222222\n",
      "f1 score corresponding to random state 107 is: 0.8205128205128205\n",
      "f1 score corresponding to random state 108 is: 0.742857142857143\n",
      "f1 score corresponding to random state 109 is: 0.7659574468085107\n",
      "f1 score corresponding to random state 110 is: 0.8125\n",
      "f1 score corresponding to random state 111 is: 0.8888888888888888\n",
      "f1 score corresponding to random state 112 is: 0.7368421052631577\n",
      "f1 score corresponding to random state 113 is: 0.7\n",
      "f1 score corresponding to random state 114 is: 0.7777777777777777\n",
      "f1 score corresponding to random state 115 is: 0.7222222222222222\n",
      "f1 score corresponding to random state 116 is: 0.7826086956521738\n",
      "f1 score corresponding to random state 117 is: 0.8\n",
      "f1 score corresponding to random state 118 is: 0.8372093023255814\n",
      "f1 score corresponding to random state 119 is: 0.7222222222222223\n",
      "f1 score corresponding to random state 120 is: 0.7179487179487181\n",
      "f1 score corresponding to random state 121 is: 0.7586206896551724\n",
      "f1 score corresponding to random state 122 is: 0.8108108108108107\n",
      "f1 score corresponding to random state 123 is: 0.8717948717948718\n",
      "f1 score corresponding to random state 124 is: 0.7407407407407408\n",
      "f1 score corresponding to random state 125 is: 0.85\n",
      "f1 score corresponding to random state 126 is: 0.8148148148148148\n",
      "f1 score corresponding to random state 127 is: 0.7317073170731708\n",
      "f1 score corresponding to random state 128 is: 0.7777777777777778\n",
      "f1 score corresponding to random state 129 is: 0.717948717948718\n",
      "f1 score corresponding to random state 130 is: 0.8648648648648649\n",
      "f1 score corresponding to random state 131 is: 0.7647058823529411\n",
      "f1 score corresponding to random state 132 is: 0.8148148148148148\n",
      "f1 score corresponding to random state 133 is: 0.8\n",
      "f1 score corresponding to random state 134 is: 0.6451612903225806\n",
      "f1 score corresponding to random state 135 is: 0.6857142857142857\n",
      "f1 score corresponding to random state 136 is: 0.8\n",
      "f1 score corresponding to random state 137 is: 0.8571428571428571\n",
      "f1 score corresponding to random state 138 is: 0.6153846153846153\n",
      "f1 score corresponding to random state 139 is: 0.7741935483870968\n",
      "f1 score corresponding to random state 140 is: 0.8823529411764706\n",
      "f1 score corresponding to random state 141 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 142 is: 0.8333333333333334\n",
      "f1 score corresponding to random state 143 is: 0.7428571428571429\n",
      "f1 score corresponding to random state 144 is: 0.6857142857142857\n",
      "f1 score corresponding to random state 145 is: 0.742857142857143\n",
      "f1 score corresponding to random state 146 is: 0.8\n",
      "f1 score corresponding to random state 147 is: 0.8148148148148148\n",
      "f1 score corresponding to random state 148 is: 0.7647058823529412\n",
      "f1 score corresponding to random state 149 is: 0.8\n",
      "f1 score corresponding to random state 150 is: 0.6976744186046512\n",
      "f1 score corresponding to random state 151 is: 0.7741935483870968\n",
      "f1 score corresponding to random state 152 is: 0.7894736842105262\n",
      "f1 score corresponding to random state 153 is: 0.6842105263157894\n",
      "f1 score corresponding to random state 154 is: 0.8125\n",
      "f1 score corresponding to random state 155 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 156 is: 0.7272727272727272\n",
      "f1 score corresponding to random state 157 is: 0.7906976744186046\n",
      "f1 score corresponding to random state 158 is: 0.7333333333333334\n",
      "f1 score corresponding to random state 159 is: 0.7777777777777778\n",
      "f1 score corresponding to random state 160 is: 0.8108108108108109\n",
      "f1 score corresponding to random state 161 is: 0.6857142857142857\n",
      "f1 score corresponding to random state 162 is: 0.9047619047619047\n",
      "f1 score corresponding to random state 163 is: 0.8936170212765957\n",
      "f1 score corresponding to random state 164 is: 0.8095238095238095\n",
      "f1 score corresponding to random state 165 is: 0.6451612903225806\n",
      "f1 score corresponding to random state 166 is: 0.7894736842105263\n",
      "f1 score corresponding to random state 167 is: 0.761904761904762\n",
      "f1 score corresponding to random state 168 is: 0.9333333333333333\n",
      "f1 score corresponding to random state 169 is: 0.7567567567567567\n",
      "f1 score corresponding to random state 170 is: 0.7999999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score corresponding to random state 171 is: 0.7692307692307692\n",
      "f1 score corresponding to random state 172 is: 0.8108108108108109\n",
      "f1 score corresponding to random state 173 is: 0.7567567567567567\n",
      "f1 score corresponding to random state 174 is: 0.9302325581395349\n",
      "f1 score corresponding to random state 175 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 176 is: 0.7222222222222223\n",
      "f1 score corresponding to random state 177 is: 0.7692307692307693\n",
      "f1 score corresponding to random state 178 is: 0.7741935483870969\n",
      "f1 score corresponding to random state 179 is: 0.6428571428571428\n",
      "f1 score corresponding to random state 180 is: 0.7894736842105263\n",
      "f1 score corresponding to random state 181 is: 0.7894736842105262\n",
      "f1 score corresponding to random state 182 is: 0.7272727272727272\n",
      "f1 score corresponding to random state 183 is: 0.7499999999999999\n",
      "f1 score corresponding to random state 184 is: 0.7333333333333334\n",
      "f1 score corresponding to random state 185 is: 0.7647058823529412\n",
      "f1 score corresponding to random state 186 is: 0.65\n",
      "f1 score corresponding to random state 187 is: 0.8235294117647058\n",
      "f1 score corresponding to random state 188 is: 0.6896551724137931\n",
      "f1 score corresponding to random state 189 is: 0.8717948717948718\n",
      "f1 score corresponding to random state 190 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 191 is: 0.8235294117647058\n",
      "f1 score corresponding to random state 192 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 193 is: 0.7428571428571429\n",
      "f1 score corresponding to random state 194 is: 0.7647058823529413\n",
      "f1 score corresponding to random state 195 is: 0.823529411764706\n",
      "f1 score corresponding to random state 196 is: 0.6666666666666666\n",
      "f1 score corresponding to random state 197 is: 0.8\n",
      "f1 score corresponding to random state 198 is: 0.7999999999999999\n",
      "f1 score corresponding to random state 199 is: 0.8571428571428572\n",
      "f1 score corresponding to random state 200 is: 0.7142857142857142\n",
      "f1 score corresponding to random state 201 is: 0.7586206896551724\n",
      "f1 score corresponding to random state 202 is: 0.8421052631578948\n",
      "f1 score corresponding to random state 203 is: 0.888888888888889\n",
      "f1 score corresponding to random state 204 is: 0.8205128205128205\n",
      "f1 score corresponding to random state 205 is: 0.8333333333333333\n",
      "f1 score corresponding to random state 206 is: 0.6976744186046512\n",
      "f1 score corresponding to random state 207 is: 0.7096774193548386\n",
      "f1 score corresponding to random state 208 is: 0.6842105263157895\n",
      "Max f2 score corresponding to  168 is:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "max_f1score = 0\n",
    "for r_state in range(42,209):\n",
    "    xtrain,xtest,ytrain,ytest = train_test_split(x,y, random_state = r_state, test_size =0.2)\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(xtrain,ytrain)\n",
    "    pred = knn.predict(xtest)\n",
    "    f1score = f1_score(ytest,pred)\n",
    "    print(\"f1 score corresponding to random state\", r_state, \"is:\", f1score)\n",
    "    \n",
    "    if f1score > max_f1score:\n",
    "        max_f1score =f1score\n",
    "        final_r_state = r_state\n",
    "print(\"Max f1 score corresponding to \",final_r_state, \"is: \", max_f1score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max f1 corresponding to random state 168 is 0.933"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55      , 0.65      , 0.55813953, 0.58536585, 0.28571429])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn,x,y,cv =5, scoring ='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# First we need to find which kernel is best among linear, poly & rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc =SVC()\n",
    "parameters ={\"kernel\":[\"linear\",\"poly\",\"rbf\"], \"C\":[0.001,0.01,0.1,1,10,100]}\n",
    "gsv =GridSearchCV(svc,parameters, cv=5, scoring='f1')\n",
    "gsv.fit(x,y)\n",
    "gsv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we got the best values using hyperparameter tuning. We insert this in to algorithm now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for random state 42 is  0.8500000000000001\n",
      "The f1 score for random state 43 is  0.8260869565217391\n",
      "The f1 score for random state 44 is  0.7906976744186047\n",
      "The f1 score for random state 45 is  0.7441860465116279\n",
      "The f1 score for random state 46 is  0.7924528301886792\n",
      "The f1 score for random state 47 is  0.8076923076923077\n",
      "The f1 score for random state 48 is  0.8421052631578947\n",
      "The f1 score for random state 49 is  0.6363636363636365\n",
      "The f1 score for random state 50 is  0.7567567567567567\n",
      "The f1 score for random state 51 is  0.7500000000000001\n",
      "The f1 score for random state 52 is  0.723404255319149\n",
      "The f1 score for random state 53 is  0.5882352941176471\n",
      "The f1 score for random state 54 is  0.6285714285714287\n",
      "The f1 score for random state 55 is  0.6857142857142857\n",
      "The f1 score for random state 56 is  0.6666666666666667\n",
      "The f1 score for random state 57 is  0.7027027027027026\n",
      "The f1 score for random state 58 is  0.7777777777777778\n",
      "The f1 score for random state 59 is  0.6511627906976744\n",
      "The f1 score for random state 60 is  0.5789473684210527\n",
      "The f1 score for random state 61 is  0.6500000000000001\n",
      "The f1 score for random state 62 is  0.8085106382978724\n",
      "The f1 score for random state 63 is  0.8666666666666667\n",
      "The f1 score for random state 64 is  0.717948717948718\n",
      "The f1 score for random state 65 is  0.7450980392156863\n",
      "The f1 score for random state 66 is  0.5789473684210527\n",
      "The f1 score for random state 67 is  0.8095238095238095\n",
      "The f1 score for random state 68 is  0.7272727272727272\n",
      "The f1 score for random state 69 is  0.7727272727272727\n",
      "The f1 score for random state 70 is  0.7346938775510204\n",
      "The f1 score for random state 71 is  0.761904761904762\n",
      "The f1 score for random state 72 is  0.8085106382978724\n",
      "The f1 score for random state 73 is  0.7441860465116279\n",
      "The f1 score for random state 74 is  0.7692307692307692\n",
      "The f1 score for random state 75 is  0.8181818181818182\n",
      "The f1 score for random state 76 is  0.6976744186046512\n",
      "The f1 score for random state 77 is  0.5853658536585366\n",
      "The f1 score for random state 78 is  0.7346938775510203\n",
      "The f1 score for random state 79 is  0.6976744186046512\n",
      "The f1 score for random state 80 is  0.7692307692307692\n",
      "The f1 score for random state 81 is  0.6842105263157895\n",
      "The f1 score for random state 82 is  0.7692307692307692\n",
      "The f1 score for random state 83 is  0.7727272727272727\n",
      "The f1 score for random state 84 is  0.8\n",
      "The f1 score for random state 85 is  0.7692307692307693\n",
      "The f1 score for random state 86 is  0.7450980392156863\n",
      "The f1 score for random state 87 is  0.7317073170731708\n",
      "The f1 score for random state 88 is  0.7317073170731707\n",
      "The f1 score for random state 89 is  0.7555555555555556\n",
      "The f1 score for random state 90 is  0.6190476190476191\n",
      "The f1 score for random state 91 is  0.6341463414634146\n",
      "The f1 score for random state 92 is  0.7428571428571429\n",
      "The f1 score for random state 93 is  0.6470588235294118\n",
      "The f1 score for random state 94 is  0.6511627906976744\n",
      "The f1 score for random state 95 is  0.851063829787234\n",
      "The f1 score for random state 96 is  0.761904761904762\n",
      "The f1 score for random state 97 is  0.7407407407407408\n",
      "The f1 score for random state 98 is  0.6486486486486486\n",
      "The f1 score for random state 99 is  0.8518518518518519\n",
      "The f1 score for random state 100 is  0.6829268292682927\n",
      "The f1 score for random state 101 is  0.888888888888889\n",
      "The f1 score for random state 102 is  0.6500000000000001\n",
      "The f1 score for random state 103 is  0.7777777777777778\n",
      "The f1 score for random state 104 is  0.84\n",
      "The f1 score for random state 105 is  0.75\n",
      "The f1 score for random state 106 is  0.5945945945945946\n",
      "The f1 score for random state 107 is  0.7142857142857143\n",
      "The f1 score for random state 108 is  0.6315789473684211\n",
      "The f1 score for random state 109 is  0.6666666666666666\n",
      "The f1 score for random state 110 is  0.6842105263157895\n",
      "The f1 score for random state 111 is  0.7692307692307692\n",
      "The f1 score for random state 112 is  0.7727272727272727\n",
      "The f1 score for random state 113 is  0.6842105263157895\n",
      "The f1 score for random state 114 is  0.6470588235294118\n",
      "The f1 score for random state 115 is  0.6976744186046512\n",
      "The f1 score for random state 116 is  0.6938775510204083\n",
      "The f1 score for random state 117 is  0.8181818181818182\n",
      "The f1 score for random state 118 is  0.8\n",
      "The f1 score for random state 119 is  0.6666666666666667\n",
      "The f1 score for random state 120 is  0.6976744186046512\n",
      "The f1 score for random state 121 is  0.6285714285714287\n",
      "The f1 score for random state 122 is  0.6829268292682926\n",
      "The f1 score for random state 123 is  0.6842105263157895\n",
      "The f1 score for random state 124 is  0.6842105263157895\n",
      "The f1 score for random state 125 is  0.851063829787234\n",
      "The f1 score for random state 126 is  0.6111111111111113\n",
      "The f1 score for random state 127 is  0.6666666666666666\n",
      "The f1 score for random state 128 is  0.761904761904762\n",
      "The f1 score for random state 129 is  0.7619047619047619\n",
      "The f1 score for random state 130 is  0.8888888888888888\n",
      "The f1 score for random state 131 is  0.6842105263157895\n",
      "The f1 score for random state 132 is  0.7222222222222223\n",
      "The f1 score for random state 133 is  0.6341463414634146\n",
      "The f1 score for random state 134 is  0.5945945945945946\n",
      "The f1 score for random state 135 is  0.75\n",
      "The f1 score for random state 136 is  0.7499999999999999\n",
      "The f1 score for random state 137 is  0.7368421052631577\n",
      "The f1 score for random state 138 is  0.761904761904762\n",
      "The f1 score for random state 139 is  0.6857142857142857\n",
      "The f1 score for random state 140 is  0.8888888888888888\n",
      "The f1 score for random state 141 is  0.7027027027027027\n",
      "The f1 score for random state 142 is  0.6956521739130435\n",
      "The f1 score for random state 143 is  0.7317073170731707\n",
      "The f1 score for random state 144 is  0.7333333333333334\n",
      "The f1 score for random state 145 is  0.6666666666666665\n",
      "The f1 score for random state 146 is  0.72\n",
      "The f1 score for random state 147 is  0.6206896551724138\n",
      "The f1 score for random state 148 is  0.7368421052631577\n",
      "The f1 score for random state 149 is  0.7000000000000001\n",
      "The f1 score for random state 150 is  0.7391304347826088\n",
      "The f1 score for random state 151 is  0.6842105263157895\n",
      "The f1 score for random state 152 is  0.7777777777777777\n",
      "The f1 score for random state 153 is  0.7391304347826088\n",
      "The f1 score for random state 154 is  0.7804878048780488\n",
      "The f1 score for random state 155 is  0.7500000000000001\n",
      "The f1 score for random state 156 is  0.7647058823529413\n",
      "The f1 score for random state 157 is  0.7499999999999999\n",
      "The f1 score for random state 158 is  0.7272727272727272\n",
      "The f1 score for random state 159 is  0.7317073170731708\n",
      "The f1 score for random state 160 is  0.7142857142857143\n",
      "The f1 score for random state 161 is  0.631578947368421\n",
      "The f1 score for random state 162 is  0.875\n",
      "The f1 score for random state 163 is  0.76\n",
      "The f1 score for random state 164 is  0.7727272727272727\n",
      "The f1 score for random state 165 is  0.7317073170731707\n",
      "The f1 score for random state 166 is  0.6666666666666667\n",
      "The f1 score for random state 167 is  0.6666666666666666\n",
      "The f1 score for random state 168 is  0.7999999999999999\n",
      "The f1 score for random state 169 is  0.7222222222222222\n",
      "The f1 score for random state 170 is  0.7647058823529412\n",
      "The f1 score for random state 171 is  0.7727272727272727\n",
      "The f1 score for random state 172 is  0.711111111111111\n",
      "The f1 score for random state 173 is  0.6666666666666666\n",
      "The f1 score for random state 174 is  0.6808510638297872\n",
      "The f1 score for random state 175 is  0.7142857142857143\n",
      "The f1 score for random state 176 is  0.5405405405405405\n",
      "The f1 score for random state 177 is  0.6829268292682927\n",
      "The f1 score for random state 178 is  0.5806451612903226\n",
      "The f1 score for random state 179 is  0.7222222222222222\n",
      "The f1 score for random state 180 is  0.8627450980392156\n",
      "The f1 score for random state 181 is  0.7555555555555556\n",
      "The f1 score for random state 182 is  0.7368421052631579\n",
      "The f1 score for random state 183 is  0.6666666666666665\n",
      "The f1 score for random state 184 is  0.6\n",
      "The f1 score for random state 185 is  0.8372093023255814\n",
      "The f1 score for random state 186 is  0.7083333333333334\n",
      "The f1 score for random state 187 is  0.8205128205128205\n",
      "The f1 score for random state 188 is  0.6190476190476191\n",
      "The f1 score for random state 189 is  0.8\n",
      "The f1 score for random state 190 is  0.6808510638297872\n",
      "The f1 score for random state 191 is  0.6666666666666665\n",
      "The f1 score for random state 192 is  0.7916666666666666\n",
      "The f1 score for random state 193 is  0.6842105263157896\n",
      "The f1 score for random state 194 is  0.7142857142857143\n",
      "The f1 score for random state 195 is  0.8717948717948718\n",
      "The f1 score for random state 196 is  0.611111111111111\n",
      "The f1 score for random state 197 is  0.6875000000000001\n",
      "The f1 score for random state 198 is  0.8095238095238095\n",
      "The f1 score for random state 199 is  0.7450980392156863\n",
      "The f1 score for random state 200 is  0.6829268292682927\n",
      "The f1 score for random state 201 is  0.6111111111111112\n",
      "The f1 score for random state 202 is  0.7441860465116279\n",
      "The f1 score for random state 203 is  0.7234042553191491\n",
      "The f1 score for random state 204 is  0.8000000000000002\n",
      "The f1 score for random state 205 is  0.7441860465116279\n",
      "The f1 score for random state 206 is  0.7843137254901961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score for random state 207 is  0.65\n",
      "The f1 score for random state 208 is  0.7058823529411765\n",
      "Max f1 state corresponding to 101 is: 0.888888888888889\n"
     ]
    }
   ],
   "source": [
    "max_f1score =0\n",
    "\n",
    "for r_state in range(42, 209):\n",
    "    xtrain,xtest,ytrain,ytest =train_test_split(x,y,random_state = r_state, test_size =0.22)\n",
    "    svc = SVC(kernel='linear', C=10)\n",
    "    svc.fit(xtrain,ytrain)\n",
    "    pred =svc.predict(xtest)\n",
    "    f1score = f1_score(ytest,pred)\n",
    "    print(\"The f1 score for random state\", r_state,\"is \", f1score)\n",
    "    \n",
    "    if f1score > max_f1score:\n",
    "        max_f1score = f1score\n",
    "        final_r_state = r_state\n",
    "        \n",
    "print(\"Max f1 state corresponding to\",final_r_state,\"is:\", max_f1score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53061224, 0.60606061, 0.66666667, 0.84444444, 0.63414634])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc,x,y,cv=5,scoring='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Val Scores of various algorithms \n",
    "1. Logistic Regression = 0.61\n",
    "2. Decission Tree Classifier =0.61\n",
    "3. KNN Classifier =0.65\n",
    "4. SVC = 0.84\n",
    "\n",
    "Of all the models SVC is having high accuracy so we will select SVC and create object file."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(svc,'sonar_svc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
